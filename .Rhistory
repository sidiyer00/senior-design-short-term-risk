amd_l0 = amd_log_rets[-2:-1]
amd_l1 = as.numeric(stats::lag(amd_log_rets,k=1))[-2:-1]
amd_l2 = as.numeric(stats::lag(amd_log_rets,k=2))[-2:-1]
lagged_df = data.frame(aapl_l0, aapl_l1, aapl_l2, amd_l0, amd_l1, amd_l2)
colnames(lagged_df) <- c("aapl_l0", "aapl_l1", "aapl_l2", "amd_l0", "amd_l1", "amd_l2")
head(lagged_df)
abs(aapl_l0)
aapl_dir = aapl_l0/abs(aapl_l0)
View(aapl_dir)
library(quantmod)
stocks = c("AAPL", "AMD")
getSymbols(stocks, from="2018-01-01", to="2021-10-14")
AAPL = AAPL$AAPL.Adjusted
AMD = AMD$AMD.Adjusted
aapl_log_rets = dailyReturn(AAPL, type="log")[-1]
amd_log_rets = dailyReturn(AMD, type="log")[-1]
aapl_l0 = aapl_log_rets[-2:-1]
aapl_l1 = as.numeric(stats::lag(aapl_log_rets,k=1))[-2:-1]
aapl_l2 = as.numeric(stats::lag(aapl_log_rets,k=2))[-2:-1]
aapl_dir = aapl_l0/abs(aapl_l0)
amd_l0 = amd_log_rets[-2:-1]
amd_l1 = as.numeric(stats::lag(amd_log_rets,k=1))[-2:-1]
amd_l2 = as.numeric(stats::lag(amd_log_rets,k=2))[-2:-1]
amd_dir = amd_l0/abs(amd_l0)
lagged_df = data.frame(aapl_l0, aapl_l1, aapl_l2, aapl_dir, amd_l0, amd_l1, amd_l2, amd_dir)
colnames(lagged_df) <- c("aapl_l0", "aapl_l1", "aapl_l2", "aapl_dir", "amd_l0", "amd_l1", "amd_l2", "amd_dir")
head(lagged_df)
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial) # Fit logistic regression [family=binomial]
aapl_l0
aapl_l0>0
(aapl_l0>0)+0
library(quantmod)
stocks = c("AAPL", "AMD")
getSymbols(stocks, from="2018-01-01", to="2021-10-14")
AAPL = AAPL$AAPL.Adjusted
AMD = AMD$AMD.Adjusted
aapl_log_rets = dailyReturn(AAPL, type="log")[-1]
amd_log_rets = dailyReturn(AMD, type="log")[-1]
aapl_l0 = aapl_log_rets[-2:-1]
aapl_l1 = as.numeric(stats::lag(aapl_log_rets,k=1))[-2:-1]
aapl_l2 = as.numeric(stats::lag(aapl_log_rets,k=2))[-2:-1]
aapl_dir = (aapl_l0>0)+0
amd_l0 = amd_log_rets[-2:-1]
amd_l1 = as.numeric(stats::lag(amd_log_rets,k=1))[-2:-1]
amd_l2 = as.numeric(stats::lag(amd_log_rets,k=2))[-2:-1]
amd_dir = (amd_l0>0)+0
lagged_df = data.frame(aapl_l0, aapl_l1, aapl_l2, aapl_dir, amd_l0, amd_l1, amd_l2, amd_dir)
colnames(lagged_df) <- c("aapl_l0", "aapl_l1", "aapl_l2", "aapl_dir", "amd_l0", "amd_l1", "amd_l2", "amd_dir")
head(lagged_df)
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
x.test = seq(from=min(x),to=max(x),by=0.01) # Test x values
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial, subset = train) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
logistic.probs.test = predict(logistic.reg , newdata=lagged_df[train, ], type="response") # Compute probabilities
# Use probabilities to make predictions
y.logistic.pred=rep(0,N) # Create repeated vector of "0"
y.logistic.pred[logistic.probs>.5] = 1 # Predict "1" if logistic regression gives greater probability to "1"
# Evaluate the accuracy
table(y.logistic.pred , y) # Confusion matrix of results
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial, subset = train) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
logistic.probs.test = predict(logistic.reg , newdata=lagged_df[-train, ], type="response") # Compute probabilities
# Use probabilities to make predictions
y.logistic.pred=rep(0,N) # Create repeated vector of "0"
y.logistic.pred[logistic.probs>.5] = 1 # Predict "1" if logistic regression gives greater probability to "1"
# Evaluate the accuracy
table(y.logistic.pred , lagged_df$aapl_l0[-train]) # Confusion matrix of results
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial, subset = train) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
logistic.probs.test = predict(logistic.reg , newdata=lagged_df[-train, ], type="response") # Compute probabilities
# Use probabilities to make predictions
y.logistic.pred=rep(0,950-760) # Create repeated vector of "0"
y.logistic.pred[logistic.probs>.5] = 1 # Predict "1" if logistic regression gives greater probability to "1"
# Evaluate the accuracy
table(y.logistic.pred , lagged_df$aapl_l0[-train]) # Confusion matrix of results
-train
length(-train)
lagged_df$aapl_l0[-train]
length(lagged_df$aapl_l0[-train])
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial, subset = train) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
logistic.probs.test = predict(logistic.reg , newdata=lagged_df[-train, ], type="response") # Compute probabilities
# Use probabilities to make predictions
y.logistic.pred=rep(0,190) # Create repeated vector of "0"
y.logistic.pred[logistic.probs>.5] = 1 # Predict "1" if logistic regression gives greater probability to "1"
# Evaluate the accuracy
table(y.logistic.pred , lagged_df$aapl_l0[-train]) # Confusion matrix of results
length(y.logistic.pred)
length(logistic.probs)
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial, subset = train) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
logistic.probs.test = predict(logistic.reg , newdata=lagged_df[-train, ], type="response") # Compute probabilities
# Use probabilities to make predictions
y.logistic.pred=rep(0,190) # Create repeated vector of "0"
y.logistic.pred[logistic.probs.test>.5] = 1 # Predict "1" if logistic regression gives greater probability to "1"
# Evaluate the accuracy
table(y.logistic.pred , lagged_df$aapl_l0[-train]) # Confusion matrix of results
logistic.acc = mean(y.logistic.pred==y) # Directly compute the accuracy
length(logistic.probs.test)
y.logistic.pred
length(y.logistic.pred)
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial, subset = train) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
logistic.probs.test = predict(logistic.reg , newdata=lagged_df[-train, ], type="response") # Compute probabilities
# Use probabilities to make predictions
y.logistic.pred=rep(0,190) # Create repeated vector of "0"
y.logistic.pred[logistic.probs.test>.5] = 1 # Predict "1" if logistic regression gives greater probability to "1"
# Evaluate the accuracy
table(y.logistic.pred , lagged_df$aapl_l0[-train]) # Confusion matrix of results
logistic.acc = mean(y.logistic.pred==y) # Directly compute the accuracy
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial, subset = train) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
logistic.probs.test = predict(logistic.reg , newdata=lagged_df[-train, ], type="response") # Compute probabilities
# Use probabilities to make predictions
y.logistic.pred=rep(0,190) # Create repeated vector of "0"
y.logistic.pred[logistic.probs.test>.5] = 1 # Predict "1" if logistic regression gives greater probability to "1"
# Evaluate the accuracy
table(y.logistic.pred , lagged_df$aapl_l0[-train]) # Confusion matrix of results
logistic.acc = mean(y.logistic.pred==lagged_df$aapl_l0[-train]) # Directly compute the accuracy
logistic.acc
# split into train and test samples
N <- nrow(lagged_df)
train = sample(N, N*.8, replace = FALSE)
logistic.reg = glm(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2 , data=lagged_df , family=binomial, subset = train) # Fit logistic regression [family=binomial]
summary(logistic.reg)
coef(logistic.reg)
summary(logistic.reg)$coef
logistic.probs=predict(logistic.reg,type="response") # Predict the probability for direction on training data
logistic.probs.test = predict(logistic.reg , newdata=lagged_df[-train, ], type="response") # Compute probabilities
# Use probabilities to make predictions
y.logistic.pred=rep(0,190) # Create repeated vector of "0"
y.logistic.pred[logistic.probs.test>.5] = 1 # Predict "1" if logistic regression gives greater probability to "1"
# Evaluate the accuracy
table(y.logistic.pred , lagged_df$aapl_l0[-train]) # Confusion matrix of results
#logistic.acc = mean(y.logistic.pred==lagged_df$aapl_l0[-train]) # Directly compute the accuracy
#logistic.acc
library("e1071")
library("e1071")
nb = naiveBayes(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2, df=lagged_df, subset=train)
nb = naiveBayes(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2, data=lagged_df, subset=train)
library("e1071")
nb = naiveBayes(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2, data=lagged_df, subset=train)
y.nb.prob = predict(nb , newdata=df.r[-train,] , type="raw") # Compute probabilities
library("e1071")
nb = naiveBayes(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2, data=lagged_df, subset=train)
y.nb.prob = predict(nb , newdata=lagged_df[-train, ] , type="raw") # Compute probabilities
y.nb.pred = (y.nb.prob[,1] < y.nb.prob[,2])+0 # 1st column is "0", 2nd column is "1"
# Evaluate the accuracy
nb.acc = mean(y.nb.pred==lagged_df$aapl_dir[-train]) # Directly compute the accuracy
nb.acc
table(y.nb.pred , lagged_df$aapl_dir[-train])
logistic.acc = mean(y.logistic.pred==lagged_df$aapl_l0[-train]) # Directly compute the accuracy
logistic.acc
library(randomForest)
library(randomForest)
library(randomForest)
rf = randomForest(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2, data=lagged_df, subset=train, ntree=300, mtry=2)
y.pred.rf = predict(rf, lagged_df[-train,])
rf.MSE = mean((y.pred.rf - lagged_df$aapl_l0[-train, ])^2)
library(randomForest)
rf = randomForest(aapl_dir~aapl_l1+aapl_l2+amd_l1+amd_l2, data=lagged_df, subset=train, ntree=300, mtry=2)
y.pred.rf = predict(rf, lagged_df[-train,])
rf.MSE = mean((y.pred.rf - lagged_df$aapl_l0[-train])^2)
rf.MSE
library(quantmod)
symbols <- c("XLK", "XLV", "XLY", "XLF", "XLI", "XLP", "XLU", "XLB", "XLE")
getSymbols(symbols, from="2012-01-01", to="2019-12-31")
library(quantmod)
symbols <- c("XLK", "XLV", "XLY", "XLF", "XLI", "XLP", "XLU", "XLB", "XLE")
getSymbols(symbols, from="2012-01-01", to="2019-12-31")
stocks = data.frame(XLK$XLK.Adjusted, XLV$XLV.Adjusted, XLY$XLY.Adjusted, XLF$XLF.Adjusted,
XLI$XLI.Adjusted, XLP$XLP.Adjusted, XLU$XLU.Adjusted, XLB$XLB.Adjusted,
XLE$XLE.Adjusted)
colnames(stocks) <- symbols
stocks
library(quantmod)
symbols <- c("XLK", "XLV", "XLY", "XLF", "XLI", "XLP", "XLU", "XLB", "XLE")
getSymbols(symbols, from="2012-01-01", to="2019-12-31")
stocks = data.frame(XLK$XLK.Adjusted, XLV$XLV.Adjusted, XLY$XLY.Adjusted, XLF$XLF.Adjusted,
XLI$XLI.Adjusted, XLP$XLP.Adjusted, XLU$XLU.Adjusted, XLB$XLB.Adjusted,
XLE$XLE.Adjusted)
colnames(stocks) <- symbols
stocks
dailyReturn(stocks)
library(quantmod)
symbols <- c("XLK", "XLV", "XLY", "XLF", "XLI", "XLP", "XLU", "XLB", "XLE")
getSymbols(symbols, from="2012-01-01", to="2019-12-31")
price_data = data.frame(XLK$XLK.Adjusted, XLV$XLV.Adjusted, XLY$XLY.Adjusted, XLF$XLF.Adjusted,
XLI$XLI.Adjusted, XLP$XLP.Adjusted, XLU$XLU.Adjusted, XLB$XLB.Adjusted,
XLE$XLE.Adjusted)
colnames(price_data) <- symbols
price_data
price_data
price_data[-1,]
rownames(price_data) <- NULL
price_data
price_data[-1,]
price_data[-length(price_data)-1,]
price_data[-1,]
price_data[-length(price_data),]
price_data[-1,]
price_data[-length(price_data),]
price_data[-1,]/price_data[-length(price_data),]
price_data[-1,]/price_data[-length(price_data),] - 1
rownames(returns_data) <- NULL
returns_data = price_data[-1,]/price_data[-length(price_data),] - 1
rownames(returns_data) <- NULL
returns_data
returns_data = price_data[-1,]/price_data[-length(price_data),] - 1
rownames(returns_data) <- NULL
returns_data
adf.test(returns_data)
library(tseries)
adf.test(returns_data)
adf.test(returns_data$XLK)
adf.test(returns_data$XLK)
setwd("C:/Users/sidiy/Documents/Projects/MGT 411")
write.csv(price_data, "sector_price_data.csv")
write.csv(price_data, "sector_price_data.csv", row.names = FALSE)
library(quantmod)
symbols <- c("XLK", "XLV", "XLY", "XLF", "XLI", "XLP", "XLU", "XLB", "XLE")
getSymbols(symbols, from="2015-01-01", to="2019-12-31")
price_data = data.frame(XLK$XLK.Adjusted, XLV$XLV.Adjusted, XLY$XLY.Adjusted, XLF$XLF.Adjusted,
XLI$XLI.Adjusted, XLP$XLP.Adjusted, XLU$XLU.Adjusted, XLB$XLB.Adjusted,
XLE$XLE.Adjusted)
colnames(price_data) <- symbols
rownames(price_data) <- NULL
price_data
returns_data = price_data[-1,]/price_data[-length(price_data),] - 1
rownames(returns_data) <- NULL
returns_data
write.csv(price_data, "sector_price_data.csv", row.names = FALSE)
library(TTR)
library(quantmod)
symbols <- c("XLK", "XLV", "XLY", "XLF", "XLI", "XLP", "XLU", "XLB", "XLE", "XLRE", "XLC")
getSymbols(symbols, from="2019-01-01", to="2021-11-12")
price_data = data.frame(XLK$XLK.Adjusted, XLV$XLV.Adjusted, XLY$XLY.Adjusted, XLF$XLF.Adjusted,
XLI$XLI.Adjusted, XLP$XLP.Adjusted, XLU$XLU.Adjusted, XLB$XLB.Adjusted,
XLE$XLE.Adjusted,XLC$XLC.Adjusted, XLRE$XLRE.Adjusted)
colnames(price_data) <- symbols
price_data
install.packages("TTR")
indicator_names <- c("SMA", "CCI", "CMO", "MACD", "BBands", "runPercentRank", "runSum", "fastK", "fastD", "slowD",
"TDI", "TRIX", "volatility","WPR","ZigZag")
indicators <- array(0, dim = c(nrow(price_data), length(indicator_names), ncol(price_data)))
dimnames(indicators)[[3]] <- symbols
rownames(indicators) <- rownames(price_data)
colnames(indicators) <- indicator_names
dimnames(indicators)
for (i in 1:ncol(price_data)){
indicators[,1,i] = as.vector(SMA(price_data[,i]))
indicators[,2,i] = as.vector(CCI(price_data[,i]))
indicators[,3,i] = as.vector(CMO(price_data[,i]))
indicators[,4,i] = as.vector(MACD(price_data[,i])[,1])
indicators[,5,i] = as.vector(BBands(price_data[,i])[,4])
indicators[,6,i] = as.vector(runPercentRank(price_data[,i]))
indicators[,7,i] = as.vector(runSum(price_data[,i]))
indicators[,8,i] = as.vector(stoch(price_data[,i])[,1]) #fastK
indicators[,9,i] = as.vector(stoch(price_data[,i])[,2])      #fastD
indicators[,10,i] = as.vector(stoch(price_data[,i])[,3])      #slowD
indicators[,11,i] = as.vector(TDI(price_data[,i])[,1])
indicators[,12,i] = as.vector(TRIX(price_data[,i])[,1])
indicators[,13,i] = as.vector(volatility(price_data[,i]))
indicators[,14,i] = as.vector(WPR(price_data[,i]))
indicators[,15,i] = as.vector(ZigZag(price_data[,i]))
}
View(indicators[,,1])
View(cor(indicators[,,1], use = "complete.obs"))
install.packages("TTR")
install.packages("TTR")
indicator_names <- c("SMA", "CCI", "CMO", "MACD", "BBands", "runPercentRank", "runSum", "fastK", "fastD", "slowD",
"TDI", "TRIX", "volatility","WPR","ZigZag")
indicators <- array(0, dim = c(nrow(price_data), length(indicator_names), ncol(price_data)))
dimnames(indicators)[[3]] <- symbols
rownames(indicators) <- rownames(price_data)
colnames(indicators) <- indicator_names
dimnames(indicators)
for (i in 1:ncol(price_data)){
indicators[,1,i] = as.vector(SMA(price_data[,i]))
indicators[,2,i] = as.vector(CCI(price_data[,i]))
indicators[,3,i] = as.vector(CMO(price_data[,i]))
indicators[,4,i] = as.vector(MACD(price_data[,i])[,1])
indicators[,5,i] = as.vector(BBands(price_data[,i])[,4])
indicators[,6,i] = as.vector(runPercentRank(price_data[,i]))
indicators[,7,i] = as.vector(runSum(price_data[,i]))
indicators[,8,i] = as.vector(stoch(price_data[,i])[,1]) #fastK
indicators[,9,i] = as.vector(stoch(price_data[,i])[,2])      #fastD
indicators[,10,i] = as.vector(stoch(price_data[,i])[,3])      #slowD
indicators[,11,i] = as.vector(TDI(price_data[,i])[,1])
indicators[,12,i] = as.vector(TRIX(price_data[,i])[,1])
indicators[,13,i] = as.vector(volatility(price_data[,i]))
indicators[,14,i] = as.vector(WPR(price_data[,i]))
indicators[,15,i] = as.vector(ZigZag(price_data[,i]))
}
return_data = data.frame(dailyReturn(XLK$XLK.Adjusted, type = "log"), dailyReturn(XLV$XLV.Adjusted, type = "log"), dailyReturn(XLY$XLY.Adjusted, type = "log"), dailyReturn(XLF$XLF.Adjusted, type = "log"),
dailyReturn(XLI$XLI.Adjusted, type = "log"), dailyReturn(XLP$XLP.Adjusted, type = "log"), dailyReturn(XLU$XLU.Adjusted, type = "log"), dailyReturn(XLB$XLB.Adjusted, type = "log"),
dailyReturn(XLE$XLE.Adjusted, type = "log"), dailyReturn(XLC$XLC.Adjusted, type = "log"), dailyReturn(XLRE$XLRE.Adjusted, type = "log"))
library(quantmod)
symbols <- c("XLK", "XLV", "XLY", "XLF", "XLI", "XLP", "XLU", "XLB", "XLE", "XLRE", "XLC")
getSymbols(symbols, from="2019-01-01", to="2021-11-12")
price_data = data.frame(XLK$XLK.Adjusted, XLV$XLV.Adjusted, XLY$XLY.Adjusted, XLF$XLF.Adjusted,
XLI$XLI.Adjusted, XLP$XLP.Adjusted, XLU$XLU.Adjusted, XLB$XLB.Adjusted,
XLE$XLE.Adjusted,XLC$XLC.Adjusted, XLRE$XLRE.Adjusted)
colnames(price_data) <- symbols
price_data
library(TTR)
indicator_names <- c("SMA", "CCI", "CMO", "MACD", "BBands", "runPercentRank", "runSum", "fastK", "fastD", "slowD", "TDI", "TRIX", "volatility","WPR","ZigZag")
indicators <- array(0, dim = c(nrow(price_data), length(indicator_names), ncol(price_data)))
dimnames(indicators)[[3]] <- symbols
rownames(indicators) <- rownames(price_data)
colnames(indicators) <- indicator_names
dimnames(indicators)
for (i in 1:ncol(price_data)){
indicators[,1,i] = as.vector(SMA(price_data[,i]))
indicators[,2,i] = as.vector(CCI(price_data[,i]))
indicators[,3,i] = as.vector(CMO(price_data[,i]))
indicators[,4,i] = as.vector(MACD(price_data[,i])[,1])
indicators[,5,i] = as.vector(BBands(price_data[,i])[,4])
indicators[,6,i] = as.vector(runPercentRank(price_data[,i]))
indicators[,7,i] = as.vector(runSum(price_data[,i]))
indicators[,8,i] = as.vector(stoch(price_data[,i])[,1]) #fastK
indicators[,9,i] = as.vector(stoch(price_data[,i])[,2])      #fastD
indicators[,10,i] = as.vector(stoch(price_data[,i])[,3])      #slowD
indicators[,11,i] = as.vector(TDI(price_data[,i])[,1])
indicators[,12,i] = as.vector(TRIX(price_data[,i])[,1])
indicators[,13,i] = as.vector(volatility(price_data[,i]))
indicators[,14,i] = as.vector(WPR(price_data[,i]))
indicators[,15,i] = as.vector(ZigZag(price_data[,i]))
}
View(indicators[,,1])
View(cor(indicators[,,1], use = "complete.obs"))
return_data = data.frame(dailyReturn(XLK$XLK.Adjusted, type = "log"), dailyReturn(XLV$XLV.Adjusted, type = "log"), dailyReturn(XLY$XLY.Adjusted, type = "log"), dailyReturn(XLF$XLF.Adjusted, type = "log"), dailyReturn(XLI$XLI.Adjusted, type = "log"), dailyReturn(XLP$XLP.Adjusted, type = "log"), dailyReturn(XLU$XLU.Adjusted, type = "log"), dailyReturn(XLB$XLB.Adjusted, type = "log"), dailyReturn(XLE$XLE.Adjusted, type = "log"), dailyReturn(XLC$XLC.Adjusted, type = "log"), dailyReturn(XLRE$XLRE.Adjusted, type = "log"))
colnames(return_data) <- symbols
View(cor(return_data))
result <- matrix(nrow = 2, ncol= ncol(return_data))
for (i in 1:ncol(return_data)){
result[1,i] <- mean(return_data[,i])
result[2,i] <- sd(return_data[,i])
}
mean(price_data[,11])
rownames(result) <- c("Mean", "Standard Deviation")
colnames(result) <- symbols
View(result)
library(quantmod)
symbols <- c("SPY", "VXX")
getSymbols(symbols, from="2018-01-25", to="2021-01-01")
price_data = data.frame(SPY$SPY.Adjusted,VXX$VXX.Adjusted)
colnames(price_data) <- symbols
library(quantmod)
symbols <- c("SPY", "VXX")
getSymbols(symbols, from="2018-01-25", to="2021-01-01")
price_data = data.frame(SPY$SPY.Adjusted,VXX$VXX.Adjusted)
colnames(price_data) <- symbols
library(TTR)
# all indicators related to the SPY
sma = as.numeric(SMA(price_data[,1]))
cci = as.numeric(CCI(price_data[,1]))
cmo = as.numeric(CMO(price_data[,1]))
macd = as.numeric(MACD(price_data[,1])[,1])
bbands = as.numeric(BBands(price_data[,1])[,4])
runSum = as.numeric(runSum(price_data[,1]))
fastK= as.numeric(stoch(price_data[,1])[,1])
fastD = as.numeric(stoch(price_data[,1])[,2])
slowD = as.numeric(stoch(price_data[,1])[,3])
tdi = as.numeric(TDI(price_data[,1])[,1])
trix = as.numeric(TRIX(price_data[,1])[,1])
volatility = as.numeric(volatility(price_data[,1]))
wpr = as.numeric(WPR(price_data[,1]))
zigZag = as.numeric(ZigZag(price_data[,1]))
# VXX daily returns
vxxReturns = dailyReturn(VXX, type="log")
indicator_df = data.frame(
sma,
cci,
cmo,
macd,
bbands,
fastK,
fastD,
slowD,
tdi,
trix,
volatility
)
indicator_df = indicator_df[complete.cases(indicator_df), ] # not lagged or logs
library(corrplot)
corrplot(cor(indicator_df, use = "complete.obs"), method = "number")
#% change df
View(indicator_df)
View(indicator_df)
library(TTR)
# all indicators related to the SPY
sma = as.numeric(SMA(price_data[,1]))
cci = as.numeric(CCI(price_data[,1]))
cmo = as.numeric(CMO(price_data[,1]))
macd = as.numeric(MACD(price_data[,1])[,1])
bbands = as.numeric(BBands(price_data[,1])[,4])
runSum = as.numeric(runSum(price_data[,1]))
fastK= as.numeric(stoch(price_data[,1])[,1])
fastD = as.numeric(stoch(price_data[,1])[,2])
slowD = as.numeric(stoch(price_data[,1])[,3])
tdi = as.numeric(TDI(price_data[,1])[,1])
trix = as.numeric(TRIX(price_data[,1])[,1])
volatility = as.numeric(volatility(price_data[,1]))
wpr = as.numeric(WPR(price_data[,1]))
zigZag = as.numeric(ZigZag(price_data[,1]))
# VXX daily returns
vxxReturns = dailyReturn(VXX, type="log")
indicator_df = data.frame(
sma,
cci,
cmo,
macd,
bbands,
fastK,
fastD,
slowD,
tdi,
trix,
volatility
)
indicator_df = indicator_df[complete.cases(indicator_df), ] # not lagged or logs
library(corrplot)
corrplot(cor(indicator_df, use = "complete.obs"), method = "number")
indicator_df2 = data.frame(
Delt(sma,type='arithmetic'),
Delt(cci,type='arithmetic'),
Delt(cmo,type='arithmetic'),
Delt(macd,type='arithmetic'),
Delt(bbands,type='arithmetic'),
Delt(fastK,type='arithmetic'),
Delt(fastD,type='arithmetic'),
Delt(slowD,type='arithmetic'),
Delt(tdi,type='arithmetic'),
Delt(trix,type='arithmetic'),
Delt(volatility,type='arithmetic')
)
colnames(indicator_df2) <- c("sma", 'cci', 'cmo', 'macd', 'bbands', 'fastK', 'fastD', 'slowD', 'tdi', 'trix', 'volatility')
rownames(indicator_df2) <- rownames(price_data)
nrow(vxxReturns)
nrow(indicator_df2)
#View(vxxReturns)
#View(indicator_df2)
###########################################################################################################################
### This modifies the lag of the model - change 7 to what you want the lag to be, and change 6 to your desired lag - 1 on the next line
#############################################################################
indicator_df2 <- indicator_df2[7:nrow(indicator_df2),]
indicator_df2$vxxReturns <-  vxxReturns[1:(nrow(vxxReturns)-6),]
indicator_df2 <- na.omit(indicator_df2)
indicator_df2 <- indicator_df2[!is.infinite(rowSums(indicator_df2)),]
#View(indicator_df2)
#indicator_df2 = indicator_df2[-na.omit(indicator_df2), ]
